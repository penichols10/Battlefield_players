{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach: Use Selenium to Load JSON\n",
    "First, a quick discussion of the [website](https://battlefieldtracker.com/bfv/leaderboards/stats/all/Wins?type=stats&page=1) layout. The previous link is to the first leaderboard page sorted by the number of games users have won. This does not in and of itself provide us with much information. But you can click on each user on the leaderboard and see an associated profile. This profile contains a lot of useful information. We would like to collect this information for every user on every page of the leaderboard.\n",
    "\n",
    "The data on the website is loaded using Javascript. This means that simply sending GET requests and parsing HTML using Python's request library will not work - the HTML will not contain the desired data as it will not have been loaded. A plausible approach is to just use Selenium to load the leaderboard pages, get the HTML once data has been loaded onto the page with Javascript, find profile URLs from the leaderboard page HTML, load the profile pages with Selenium, then go through the profile page HTML to find data. There are two problems with this approach, both associated with page loading times. First, page loading times vary. To scrape a dynamic page in this fashion, first Selenium starts loading the page. Then the program waits for some set time. After waiting, Selenium passes the loaded page's HTML to BeautifulSoup for parsing. But if the page isn't loaded, the program could crash or at best there will be missing data. To prevent this, the program has to wait for several seconds for pages to load, which becomes prohibitively slow to scrape the whole site. Second, the pages just generally load slowly. This method would have taken several days even with a reasonably low loss rate of around 1% of the data.\n",
    "\n",
    "A second approach requires determining if the website gets its data from an API. If it does, you may use the API to load the data in JSON format. The advantages here are that you do not have to spend time loading the actual pages, there is data in the API that is not loaded on the page, and the API stores data in a more human readable format than on in the HTML. To find the API, load the page in a browser (I use Firefox for this). Open the developer tools panel with the F12 key. Click the Network tab on the panel and the XHR button on the row below that. Reload the page. The list should populate, and if you look for requests with Type JSON, you should eventually find the API urls. You can use a tool like Insomnia to quickly generate code to make requests to the API with Python. The problem in this case is the APIs did not accept requests.\n",
    "\n",
    "The third and final approach combines the previous. I use the API, but I use Selenium to load the response to API requests in the browser rather than the pages that display data from the API. These are in JSON format and load nearly instantly. This eliminates or reduces the downsides of the first approach (slow, lost data) and retains most of the benefits of the second approach (faster, no lost data, more features). For scale, this probably speeds up the scraping process by about an order of magnitude, with no lost data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaderboard\n",
    "The first step is to get data from the leaderboard page itself. Since so much data can be retrived from the API that loads the profile pages, all that is needed from the leaderboard are the names of players and platforms they play on. The players usernames and platforms are combined to make a features I call \"player_id.\" These take the form (platform_abbreviation)/(username). In addition to serving as identifiers for players, they are needed to get unique information about players from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = {}\n",
    "def parse_player(player_json):\n",
    "    '''\n",
    "    Retrives the players username and platform and returns their player_id and platform\n",
    "    Parameters: player_json, the portion of a JSON string from the leaderboard API associated with a player.\n",
    "    Returns: player_id, player_platform\n",
    "    '''\n",
    "    player_username = player_json['id']\n",
    "    player_platform = player_json['owner']['metadata']['platformSlug']\n",
    "    player_id = f'{player_platform}/{player_username}'\n",
    "    \n",
    "    return player_id, player_platform\n",
    "\n",
    "def parse_leaderboard(leaderboard_url, stat_dict):\n",
    "    '''\n",
    "    Retrives the player_id and player_platform for every play on a leaderboard page\n",
    "    Parameters: leaderboard_url (url for the leaderboard API for a page), stat_dict (dictionary of player performance metrics and other player information)\n",
    "    '''\n",
    "\n",
    "    # Load the URL\n",
    "    driver.get(leaderboard_url)\n",
    "    leaderboard_content = driver.page_source.encode('utf-8').strip()\n",
    "    soup = bs(leaderboard_content)\n",
    "    leaderboard_json = json.loads(soup.body.pre.text)\n",
    "\n",
    "    if 'data' in leaderboard_json:\n",
    "        leaderboard_data_json = leaderboard_json['data']['items']\n",
    "        # Get names from leaderboard\n",
    "        for player_json in leaderboard_data_json:\n",
    "            player_id, player_platform = parse_player(player_json)\n",
    "            # Add the player_id to the dictionary\n",
    "            if 'player_id' in stat_dict:\n",
    "                stat_dict['player_id'].append(player_id)\n",
    "            else:\n",
    "                stat_dict['player_id'] = [player_id]\n",
    "\n",
    "            # Add the player platform to the dictionary\n",
    "            if 'platform' in stat_dict:\n",
    "                stat_dict['platform'].append(player_platform)\n",
    "            else:\n",
    "                stat_dict['platform'] = [player_platform]\n",
    "\n",
    "    else:\n",
    "        if 'player_id' not in stat_dict:\n",
    "            stat_dict['player_id'] = []\n",
    "            stat_dict['platform'] = []\n",
    "            \n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile\n",
    "The second step is to scrape data from the player profiles. The profile consists of two broad categories of data. First, overall information, which is referred to as player \"history.\" These are metric calculated accross class like kills, score, etc. Second, there are specific metrics broken out by class and vehicle use. All of these are stored in easy to navigate JSON strings, but they each require different API requests. In both categories, stats are given in raw format (ex. 10000 in the score feature means the player's total score while playing has been 10000) and percentile format (ex. 1.9 in the score feature means the player is in the 1.9% of highest scorign players). These are given different suffixes - _value and _score - to make them identifiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall History\n",
    "The first thing I retrieve is player history information. This is a simple matter of looping over different performance metrics and storing information in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_history_for_player(history_json, stat_dict, history_categories):\n",
    "    available_stats = history_json.keys()\n",
    "    for stat in history_categories:\n",
    "        if stat in available_stats:\n",
    "            stat_value = history_json[stat]['value']\n",
    "            stat_percentile = history_json[stat]['percentile']\n",
    "        else:\n",
    "            stat_value = np.nan\n",
    "            stat_percentile = np.nan\n",
    "        \n",
    "        # Add value to stat_dict\n",
    "        if stat+'_value' in stat_dict:\n",
    "            stat_dict[stat+'_value'].append(stat_value)\n",
    "        else:\n",
    "            stat_dict[stat+'_value'] = [stat_value]\n",
    "            \n",
    "        # Add percentile to stat_dict\n",
    "        if stat+'_percentile' in stat_dict:\n",
    "            stat_dict[stat+'_percentile'].append(stat_percentile)\n",
    "        else:\n",
    "            stat_dict[stat+'_percentile'] = [stat_percentile]\n",
    "\n",
    "    return stat_dict  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class stats\n",
    "The first thing I retrieve is player class information. This is a simple matter of looping over different performance metrics and storing information in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_class_stats(class_json, stat_dict, class_categories):\n",
    "    '''\n",
    "    Retrieve class-specific stats for a specific player for a single class.\n",
    "    '''\n",
    "    class_name = class_json['metadata']['name']\n",
    "    available_stats = list(class_json['stats'].keys())[1:]\n",
    "\n",
    "    # Add class stats to stat_dict       \n",
    "    for stat in class_categories: # The first entry is player rank, which we don't need\n",
    "        # Check if the desired stat is present in the JSON\n",
    "        if stat in available_stats:\n",
    "            stat_percentile = class_json['stats'][stat]['percentile']\n",
    "            stat_value = class_json['stats'][stat]['value']\n",
    "        else:\n",
    "            stat_percentile = np.nan\n",
    "            stat_value = np.nan\n",
    "        \n",
    "        stat_name = f'{class_name}_{stat}' # ex Assault_kills\n",
    "        \n",
    "        # Add stat value to dictionary\n",
    "        if stat_name+'_value' in stat_dict:\n",
    "            stat_dict[stat_name+'_value'].append(stat_value)\n",
    "        else:\n",
    "            stat_dict[stat_name+'_value'] = [stat_value]\n",
    "        \n",
    "        # Add stat percentile to dictionary\n",
    "        if stat_name+'_percentile' in stat_dict:\n",
    "            stat_dict[stat_name+'_percentile'].append(stat_percentile)\n",
    "        else:\n",
    "            stat_dict[stat_name+'_percentile'] = [stat_percentile]\n",
    "            \n",
    "    return stat_dict\n",
    "\n",
    "def parse_classes_for_player(classes_json, stat_dict, class_categories):\n",
    "    '''\n",
    "    Retrieve class-specific stats for a specific player for all classes.\n",
    "    '''\n",
    "    classes = ['medic', 'assault', 'support', 'recon', 'tanker', 'pilot']\n",
    "    for class_json in classes_json:\n",
    "        stat_dict = parse_class_stats(class_json, stat_dict, class_categories)\n",
    "    \n",
    "    # Check to see if class data was found for all classes for the player - some players do not have data for certain classes\n",
    "    # First, identify class related features\n",
    "    class_features = []\n",
    "    for player_class in classes:\n",
    "        for feature in stat_dict:\n",
    "            if player_class in feature.lower():\n",
    "                class_features.append(feature)\n",
    "    \n",
    "    # Check to see if all class related features are of same length, if not, fill short features with NaN      \n",
    "    feature_lengths = [len(stat_dict[feature]) for feature in class_features]\n",
    "    unique_feature_lengths = set(feature_lengths)\n",
    "    if len(unique_feature_lengths) > 1:\n",
    "        num_samples = max(unique_feature_lengths)\n",
    "        for i, feature_length in enumerate(feature_lengths):\n",
    "            if feature_length < num_samples:\n",
    "                short_feature = class_features[i]\n",
    "                stat_dict[short_feature].append(np.nan) # Since we do this for each player, should never need to add more than 1 NaN per player\n",
    "                    \n",
    "    return stat_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Code and Automate Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_player_stats(stat_dict, history_categories, class_categories):\n",
    "    for player_id in tqdm(stat_dict['player_id']):\n",
    "        \n",
    "        # Get overall history for player\n",
    "        api_url = f\"https://api.tracker.gg/api/v2/bfv/standard/profile/{player_id}?\"\n",
    "\n",
    "        driver.get(api_url)\n",
    "        history_content = driver.page_source.encode('utf-8').strip()\n",
    "        soup = bs(history_content)\n",
    "        history_json = json.loads(soup.body.pre.text)\n",
    "\n",
    "        # Some data is simply unavailable for access\n",
    "        if 'data' in history_json:\n",
    "            history_json_data = history_json['data']['segments'][0]['stats']\n",
    "\n",
    "            stat_dict = parse_history_for_player(history_json_data, stat_dict, history_categories)\n",
    "               \n",
    "        # Get class info for the user in question\n",
    "        api_url = f\"https://api.tracker.gg/api/v2/bfv/standard/profile/{player_id}/segments/class\"\n",
    "\n",
    "        driver.get(api_url)\n",
    "        class_content = driver.page_source.encode('utf-8').strip()\n",
    "        soup = bs(class_content)\n",
    "\n",
    "        classes_json = json.loads(soup.body.pre.text)\n",
    "        if 'data' in classes_json:\n",
    "            classes_json_data = classes_json['data']\n",
    "            \n",
    "            stat_dict = parse_classes_for_player(classes_json_data, stat_dict, class_categories)\n",
    "\n",
    "        # Drop player if no associated information\n",
    "        if 'data' not in history_json and 'data' not in classes_json:\n",
    "            stat_dict['player_id'] = stat_dict['player_id'][:-1]\n",
    "            stat_dict['platform'] = stat_dict['platform'][:-1]\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        \n",
    "    return stat_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 105.0.5195\n",
      "[WDM] - Get LATEST chromedriver version for 105.0.5195 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\Patrick\\.wdm\\drivers\\chromedriver\\win32\\105.0.5195.52\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping first 40800 profiles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:10<00:00,  3.71s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.49s/it]\n",
      "100%|██████████| 100/100 [05:54<00:00,  3.54s/it]\n",
      "100%|██████████| 100/100 [05:42<00:00,  3.42s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:52<00:00,  3.52s/it]\n",
      "100%|██████████| 100/100 [05:44<00:00,  3.45s/it]\n",
      "100%|██████████| 100/100 [05:48<00:00,  3.49s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.49s/it]\n",
      "100%|██████████| 100/100 [05:46<00:00,  3.47s/it]\n",
      "100%|██████████| 100/100 [05:45<00:00,  3.45s/it]\n",
      "100%|██████████| 100/100 [05:51<00:00,  3.51s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.49s/it]\n",
      "100%|██████████| 100/100 [05:48<00:00,  3.48s/it]\n",
      "100%|██████████| 100/100 [05:53<00:00,  3.54s/it]\n",
      "100%|██████████| 100/100 [05:53<00:00,  3.54s/it]\n",
      "100%|██████████| 100/100 [05:55<00:00,  3.56s/it]\n",
      "100%|██████████| 100/100 [06:01<00:00,  3.61s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [06:03<00:00,  3.63s/it]\n",
      "100%|██████████| 100/100 [05:56<00:00,  3.56s/it]\n",
      "100%|██████████| 100/100 [06:01<00:00,  3.61s/it]\n",
      "100%|██████████| 100/100 [05:59<00:00,  3.60s/it]\n",
      "100%|██████████| 100/100 [05:51<00:00,  3.52s/it]\n",
      "100%|██████████| 100/100 [06:11<00:00,  3.71s/it]\n",
      "100%|██████████| 100/100 [06:08<00:00,  3.68s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:55<00:00,  3.56s/it]\n",
      "100%|██████████| 100/100 [05:50<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [06:13<00:00,  3.73s/it]\n",
      "100%|██████████| 100/100 [05:55<00:00,  3.55s/it]\n",
      "100%|██████████| 100/100 [05:47<00:00,  3.47s/it]\n",
      "100%|██████████| 100/100 [05:52<00:00,  3.53s/it]\n",
      "100%|██████████| 100/100 [05:52<00:00,  3.52s/it]\n",
      "100%|██████████| 100/100 [06:35<00:00,  3.95s/it]\n",
      "100%|██████████| 100/100 [05:58<00:00,  3.58s/it]\n",
      "100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n",
      "100%|██████████| 100/100 [05:52<00:00,  3.53s/it]\n",
      "100%|██████████| 100/100 [05:53<00:00,  3.53s/it]\n",
      "100%|██████████| 100/100 [06:12<00:00,  3.73s/it]\n",
      "100%|██████████| 100/100 [06:03<00:00,  3.63s/it]\n",
      "100%|██████████| 100/100 [06:07<00:00,  3.67s/it]\n",
      "100%|██████████| 100/100 [06:15<00:00,  3.75s/it]\n",
      "100%|██████████| 100/100 [05:57<00:00,  3.58s/it]\n",
      "100%|██████████| 100/100 [06:13<00:00,  3.73s/it]\n",
      "100%|██████████| 100/100 [05:49<00:00,  3.50s/it]\n",
      "100%|██████████| 100/100 [05:56<00:00,  3.56s/it]\n",
      "100%|██████████| 100/100 [05:47<00:00,  3.48s/it]\n",
      "100%|██████████| 100/100 [06:00<00:00,  3.60s/it]\n",
      "100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n",
      "100%|██████████| 100/100 [05:53<00:00,  3.53s/it]\n",
      "100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n",
      "100%|██████████| 100/100 [06:00<00:00,  3.60s/it]\n",
      "100%|██████████| 100/100 [06:34<00:00,  3.95s/it]\n",
      "100%|██████████| 100/100 [06:21<00:00,  3.82s/it]\n",
      "100%|██████████| 100/100 [06:07<00:00,  3.68s/it]\n",
      "100%|██████████| 100/100 [05:56<00:00,  3.56s/it]\n",
      "100%|██████████| 100/100 [06:05<00:00,  3.66s/it]\n",
      "100%|██████████| 100/100 [06:12<00:00,  3.73s/it]\n",
      "100%|██████████| 100/100 [06:10<00:00,  3.70s/it]\n",
      "100%|██████████| 100/100 [06:20<00:00,  3.81s/it]\n",
      "100%|██████████| 100/100 [06:23<00:00,  3.83s/it]\n",
      "100%|██████████| 100/100 [06:31<00:00,  3.91s/it]\n",
      "100%|██████████| 100/100 [06:58<00:00,  4.19s/it]\n",
      "100%|██████████| 100/100 [06:28<00:00,  3.88s/it]\n",
      "100%|██████████| 100/100 [06:20<00:00,  3.81s/it]\n",
      "  7%|▋         | 7/100 [00:28<06:21,  4.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_94624/4206510841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mhistory_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'categories_to_scrape.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mscrape_site\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_94624/4206510841.py\u001b[0m in \u001b[0;36mscrape_site\u001b[1;34m(history_categories, class_categories)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# scrape page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mstat_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mstat_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaderboard_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mkey_lens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstat_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_lens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_94624/4206510841.py\u001b[0m in \u001b[0;36mscrape_page\u001b[1;34m(leaderboard_url, stat_dict, history_categories, class_categories)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Scrape the page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstat_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_leaderboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaderboard_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstat_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mstat_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_player_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstat_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_94624/3900204239.py\u001b[0m in \u001b[0;36mparse_player_stats\u001b[1;34m(stat_dict, history_categories, class_categories)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mapi_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"https://api.tracker.gg/api/v2/bfv/standard/profile/{player_id}?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mhistory_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \"\"\"\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     76\u001b[0m             )\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1347\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1350\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def read_categories(categories_to_scrape_file):\n",
    "    with open(categories_to_scrape_file, 'r') as f:\n",
    "        categories = f.read().split('\\n')\n",
    "        history_categories = categories[0].split(' ')\n",
    "        class_categories = categories[1].split(' ')\n",
    "    return history_categories, class_categories\n",
    "\n",
    "def scrape_page(leaderboard_url, stat_dict, history_categories, class_categories):\n",
    "    # Scrape the page\n",
    "    stat_dict = parse_leaderboard(leaderboard_url, stat_dict)\n",
    "    stat_dict = parse_player_stats(stat_dict, history_categories, class_categories)\n",
    "    \n",
    "    return stat_dict\n",
    "\n",
    "def scrape_site(history_categories, class_categories):\n",
    "    # determine how many profiles to skip\n",
    "    skip = 0\n",
    "    files = os.listdir('data')\n",
    "    if len(files) > 0:\n",
    "        file_nums = map(lambda x: int(x.split('p')[1].split('.')[0]), files)\n",
    "        skip = max(list(file_nums)) + 100\n",
    "        print(f'Skipping first {skip} profiles.')\n",
    "\n",
    "    while skip < 78800:\n",
    "        leaderboard_url = f'https://api.tracker.gg/api/v1/bfv/standard/leaderboards?type=stats&platform=all&board=WINS&skip={skip}&take=100'\n",
    "        \n",
    "        # scrape page\n",
    "        stat_dict = {}\n",
    "        stat_dict = scrape_page(leaderboard_url, stat_dict, history_categories, class_categories)\n",
    "        key_lens = [len(stat_dict[key]) for key in stat_dict]\n",
    "        if len(list(set(key_lens))) > 1:\n",
    "            for key in stat_dict:\n",
    "                print(key, len(stat_dict[key]))\n",
    "\n",
    "\n",
    "        # Load previous progess, if any\n",
    "        current_iter = pd.DataFrame.from_dict(stat_dict)\n",
    "        previous_file_name = f'bfvstats_skip{skip-100}.csv'\n",
    "        \n",
    "        if previous_file_name in files:\n",
    "            previous_iter = pd.read_csv('data/'+previous_file_name, index_col=0)\n",
    "            combined_df = pd.concat([previous_iter, current_iter]).reset_index(drop=True)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['player_id'])\n",
    "\n",
    "            # os.remove(previous_file_name) T\n",
    "            combined_df.to_csv(f'data/bfvstats_skip{skip}.csv')\n",
    "            current_iter.to_sql('bfvstats', con=con, if_exists='append')\n",
    "                     \n",
    "            \n",
    "        else:\n",
    "            current_iter.to_csv(f'data/bfvstats_skip{skip}.csv')\n",
    "            current_iter.to_sql('bfvstats', con=con, if_exists='append')\n",
    "\n",
    "        skip += 100\n",
    "\n",
    "con = sqlite3.connect('bfvstats.db')\n",
    "cur = con.cursor()\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "history_categories, class_categories = read_categories('categories_to_scrape.txt')\n",
    "\n",
    "scrape_site(history_categories, class_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0480a40de60fe0b4be044949303dbe98ce3610184aeb132e77bccbcbbb8df2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
